{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from benchmark_models import *\n",
    "from oneclass-selfattention import *\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading and Processing Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.npy', 'rb') as f:\n",
    "    X, Y = np.load(f)\n",
    "\n",
    "#standardization    \n",
    "std_X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Modeling </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate of anomalies\n",
    "ano_rate = 0.02\n",
    "#test and valid rate\n",
    "test_rate = 0.2\n",
    "valid_rate = 0.2\n",
    "\n",
    "#Auto encoder architectures for finetuning\n",
    "auto_encoder_architectures = [\n",
    "    [[16,64], [8,32], [8,32],[16,64]],\n",
    "    [[[16,64], [8,32], [8,32],[16,64]],\n",
    "    [[32,128], [16,64], [16,64],[32,128]],\n",
    "    [[16,64], [8,32], [4,32]], [[4,32],[8,32],[16,64]],\n",
    "    [[32,128], [16,64], [8,32], [8,32],[16,64],[32,128]],\n",
    "    [[32,128], [16,64], [8,32], [4,32]], [[4,32],[8,32],[16,64],[32,128]],\n",
    "]\n",
    "    \n",
    "#Deep One-Class architectures for finetuning\n",
    "one_class_architectures = [\n",
    "    [[32,64],[16,32],[8,32]],\n",
    "    [[64,128],[32,64],[16,32]],\n",
    "    [[64,128],[64,128],[32,64],[16,32]],\n",
    "    [[64,128],[32,64],[32,64],[16,32]],\n",
    "    [[64,128],[32,64],[16,32],[8,32]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture alloutput\n",
    "\n",
    "OCSVMF1 = []\n",
    "IFF1 = []\n",
    "AEF1 = []\n",
    "AESVMF1 = []\n",
    "DOCCF1 = []\n",
    "OCSAv1F1 = []\n",
    "OCSAv2F1 = []\n",
    "\n",
    "for seed in [111111,222222,333333,444444,555555,666666,777777,888888,999999,121212]:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #split train/set\n",
    "    trvX, testX, trvY, testY = train_test_split(X, Y, test_rate)\n",
    "    trainX, validX, trainY, validY = train_test_split(trvX, trvY, valid_rate)\n",
    "\n",
    "   \n",
    "    #################\n",
    "    #################\n",
    "    ########One Class Support Vector Machine\n",
    "    #grid search for gamma\n",
    "    param_grid = {\n",
    "        'gamma' : [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'nu' : [0.01, 0.05 ,0.1, 0.15]\n",
    "    }\n",
    "    grid_search = GridSearchCV(OneClassSVM(kernel='rbf'), param_grid, cv=10, scoring='f1_score')\n",
    "    grid_search.fit(trvX, trvY)\n",
    "    testY_pred = grid_search.best_estimator_.predict(testX)\n",
    "    OCSVMF1.append(f1_score(testY, testY_pred, pos_label=-1))\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    #################\n",
    "    #########Isolation forest\n",
    "    #grid search for n_estimators\n",
    "    param_grid = {'n_estimators' : [25, 50, 100, 150, 200]}\n",
    "    grid_search = GridSearchCV(IsolationForest(contamination=ano_rate), param_grid, cv=10, scoring='f1_score')\n",
    "    grid_search.fit(trvX, trvY)\n",
    "    testY_pred = grid_search.best_estimator_.predict(testX)\n",
    "    IFF1.append(f1_score(testY, testY_pred, pos_label=-1))\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    #################\n",
    "    ###########Auto Encoder\n",
    "    models = []\n",
    "    f1s_list = []\n",
    "    for architecture in auto_encoder_architectures:\n",
    "        cnn = CNN1D_AE(X.shape[1], architecture)\n",
    "        cnn.train(1000,1.0,trainX)\n",
    "        valY_pred = cnn.predict(validX)\n",
    "        f1s_list.append(f1_score(valY, valY_pred, pos_label=-1))\n",
    "    best_ae = models[f1s_list.index(max(f1s_list))]\n",
    "    testY_pred = best_ae.predict(testX,ano_rate)\n",
    "    AEF1.append(f1_score(testY, predY, pos_label=-1))\n",
    "    \n",
    "    #generate encoded data from auto encoder\n",
    "    trvX_Enc = cnn.encode(trvX)\n",
    "    trvX_Enc = trvX_Enc.reshape(trvX_Enc.shape[0], trvX_Enc.shape[1]*trvX_Enc.shape[2])\n",
    "    testX_Enc = cnn.encode(testX)\n",
    "    testX_Enc = testX_Enc.reshape(testX_Enc.shape[0], testX_Enc.shape[1]*testX_Enc.shape[2])\n",
    "    \n",
    "    #turn off all auto-encoder models\n",
    "    for model in models:\n",
    "        model.close()\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    #################    \n",
    "    ###########Auto Encoder --- One Class SVM\n",
    "    #grid search for gamma\n",
    "    param_grid = {\n",
    "        'gamma' : [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'nu' : [0.01, 0.05 ,0.1, 0.15]\n",
    "    }\n",
    "    grid_search = GridSearchCV(OneClassSVM(kernel='rbf'), param_grid, cv=10, scoring='f1_score')\n",
    "    grid_search.fit(trvX_Enc, trvY)\n",
    "    testY_pred = grid_search.best_estimator_.predict(testX_Enc)\n",
    "    AESVMF1.append(f1_score(testY, testY_pred, pos_label=-1))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #################\n",
    "    #################\n",
    "    #######Deep One-Class Classifier --- finetune externally\n",
    "    #finetune architectures\n",
    "    models = []\n",
    "    f1s_list = []\n",
    "    for architecture in one_class_architectures:\n",
    "        cnn = DOCC(X.shape[1], architecture, 64)\n",
    "        cnn.initialize(trainX)\n",
    "        cnn.train(50,1e-4,trainX, min_epochs=10, min_improvement=0.01)\n",
    "        valY_pred = cnn.predict(validX)\n",
    "        f1s_list.append(f1_score(valY, valY_pred, pos_label=-1))\n",
    "    docc = models[f1s_list.index(max(f1s_list))]\n",
    "    predY = docc.predict(testX,ano_rate)\n",
    "    DOCCF1.append(f1_score(testY, predY, pos_label=-1))\n",
    "    \n",
    "    #turn off all auto-encoder models\n",
    "    for model in models:\n",
    "        model.close()\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    #################\n",
    "    #######One-Class Self-Attention --- v1\n",
    "    models = []\n",
    "    f1s_list = []\n",
    "    for architecture in one_class_architectures:\n",
    "        cnn = OneClassSelfAttention(X.shape[1], architecture, 64)\n",
    "        cnn.initialize(trainX)\n",
    "        cnn.train(50,1e-4,trainX, min_epochs=10, min_improvement=0.01)\n",
    "        valY_pred = cnn.predict(validX)\n",
    "        f1s_list.append(f1_score(valY, valY_pred, pos_label=-1))\n",
    "    ocsav1 = models[f1s_list.index(max(f1s_list))]\n",
    "    predY = ocsav1.predict(testX,ano_rate)\n",
    "    OCSAv1F1.append(f1_score(testY, predY, pos_label=-1))\n",
    "    \n",
    "    #turn off all auto-encoder models\n",
    "    for model in models:\n",
    "        model.close()\n",
    "        \n",
    "    \n",
    "    #################\n",
    "    #################\n",
    "    #######One-Class Self-Attention --- v2\n",
    "    models = []\n",
    "    f1s_list = []\n",
    "    for architecture in one_class_architectures:\n",
    "        cnn = OneClassSelfAttention(X.shape[1], architecture, 64, ver=2)\n",
    "        cnn.train(50,1e-4,trainX, min_epochs=10, min_improvement=0.01)\n",
    "        valY_pred = cnn.predict(validX)\n",
    "        f1s_list.append(f1_score(valY, valY_pred, pos_label=-1))\n",
    "    ocsav2 = models[f1s_list.index(max(f1s_list))]\n",
    "    predY = ocsav2.predict(testX,ano_rate)\n",
    "    OCSAv2F1.append(f1_score(testY, predY, pos_label=-1))\n",
    "    \n",
    "    #turn off all auto-encoder models\n",
    "    for model in models:\n",
    "        model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f1 in [OCSVMF1, IFF1, AEF1, AESVMF1, DOCCF1, OCTv1F1, OCTv2F1]:\n",
    "    print(np.mean(f1), np.std(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
